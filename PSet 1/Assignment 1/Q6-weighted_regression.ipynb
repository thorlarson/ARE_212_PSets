{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Regression in =python=\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that $T$ and $u$ are &ldquo;independent&rdquo; (or at least\n",
    "orthogonal) variables means that if we want to compute a\n",
    "&ldquo;classical&rdquo; regression we&rsquo;d do it something like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define independent random variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "np.random.seed(seed=90210)\n",
    "k = 3 # Number of observables in T\n",
    "\n",
    "mu = [0]*k\n",
    "Sigma=[[1,0.5,0],\n",
    "       [0.5,2,0],\n",
    "       [0,0,3]]\n",
    "\n",
    "T = multivariate_normal(mu,Sigma)\n",
    "\n",
    "U = multivariate_normal(cov=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define =X=\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $X$ can depend on $T$ and $u$.  This dependence needn&rsquo;t be\n",
    "linear!  For example, suppose $X=T^3D + u$, where $D$ is an\n",
    "$\\ell\\times k$ matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct Sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct a sample of observables $(y,X,T)$ we just use the regression equation,\n",
    "      plus an assumption about the value of $\\beta$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = [1/2,1]\n",
    "beta2 = [-2,4]\n",
    "beta = np.reshape([beta1,beta2],(2,2))\n",
    "m = 2\n",
    "C = [[1,-0],[-0,1]] # True error covariance\n",
    "C = np.reshape(C,(-1,m))\n",
    "\n",
    "D = np.random.random(size=(3,2)) # Generate random 3x2 matrix\n",
    "\n",
    "N=1000 # Sample size\n",
    "\n",
    "# Now: Transform rvs into a sample\n",
    "t = T.rvs(N)\n",
    "\n",
    "u = U.rvs(N) # Replace u with a sample\n",
    "v = U.rvs(N) #Ensures the first N entries match those from weighted_regression.py\n",
    "\n",
    "\n",
    "X = (t**3)@D  # Note use of ** operator for exponentiation\n",
    "\n",
    "y = X@beta + (C@[u,v]).T # Note use of @ operator for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape((C@[u,v]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Turn to estimation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we now have data on *realizations* $(y,X,T)$.  Now forget\n",
    "     that we know $\\beta$ and let&rsquo;s estimate it, using weighted least\n",
    "     squares.  As a numerical matter it&rsquo;s better to avoid explicitly\n",
    "     inverting the $(T^T X)$ matrix; instead we can solve the &ldquo;normal&rdquo;\n",
    "     equations\n",
    "\n",
    "\\begin{align*}\n",
    "   X'y &= X' X b + X' u\\\\\n",
    "   \\mbox{E}(T'u) = 0\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numerical solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classical case we were trying to solve a linear system that\n",
    " took the form $Ab=0$, with $A$ a square matrix.  In the present case\n",
    " we&rsquo;re also trying to solve a linear system, but with a matrix $A$\n",
    " that may have more rows than columns.  Provided the rows are linearly\n",
    " independent, this implies that we have an **overidentified** system of\n",
    " equations.  We&rsquo;ll return to the implications of this later, but for\n",
    " now this also calls for a different numerical approach, using\n",
    " `np.linalg.lstsq` instead of `np.linalg.solve`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.87417906  2.1688006 ]\n",
      " [-3.48727804  6.05128036]]\n",
      "[[ 0.20060124 -0.02247382]\n",
      " [-0.02247382  0.2163604 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54/96655108.py:3: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  b = np.linalg.lstsq(t.T@X,t.T@y)[0] # lstsqs returns several results; we pick the first\n",
      "/tmp/ipykernel_54/96655108.py:17: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  b2 = np.linalg.lstsq(t.T@Om_inv@X,t.T@Om_inv@y)[0] # lstsqs returns several results; we pick the first\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import inv, sqrtm\n",
    "\n",
    "b = np.linalg.lstsq(t.T@X,t.T@y)[0] # lstsqs returns several results; we pick the first\n",
    "\n",
    "e = y - X@b\n",
    "\n",
    "\n",
    "TXplus = np.linalg.pinv(t.T@X) # Moore-Penrose pseudo-inverse\n",
    "\n",
    "# Empirical covariance matrix of e\n",
    "Omega_hat = np.cov(e)\n",
    "Om_inv = np.linalg.pinv(Omega_hat) #This doesn't seem to be properly inverting the matrix \n",
    "#np.linalg.pinv(Omega_hat) @ Omega_hat doesn't return the identity.\n",
    "\n",
    "TXplus2 = np.linalg.pinv(t.T@Om_inv@X)\n",
    "\n",
    "b2 = np.linalg.lstsq(t.T@Om_inv@X,t.T@Om_inv@y)[0] # lstsqs returns several results; we pick the first\n",
    "print(b2)\n",
    "\n",
    "e2 = y - X@b2\n",
    "print(np.cov(e.T))\n",
    "    \n",
    "# vb = e2.var()*TXplus2@t.T@Omega_hat@t@TXplus2.T  # This code should work if the above works properly\n",
    "# print(vb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20060124, -0.02247382],\n",
       "       [-0.02247382,  0.2163604 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(e.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.10947343e-04,  1.23018210e-03,  2.64998000e-05, ...,\n",
       "        -8.67545461e-04, -5.35605863e-04, -1.99754835e-05],\n",
       "       [ 1.23018210e-03,  3.68258373e-03,  7.93278753e-05, ...,\n",
       "        -2.59702104e-03, -1.60335079e-03, -5.97971557e-05],\n",
       "       [ 2.64998000e-05,  7.93278753e-05,  1.70883061e-06, ...,\n",
       "        -5.59433746e-05, -3.45383623e-05, -1.28811228e-06],\n",
       "       ...,\n",
       "       [-8.67545461e-04, -2.59702104e-03, -5.59433746e-05, ...,\n",
       "         1.83146366e-03,  1.13071040e-03,  4.21699771e-05],\n",
       "       [-5.35605863e-04, -1.60335079e-03, -3.45383623e-05, ...,\n",
       "         1.13071040e-03,  6.98078831e-04,  2.60349319e-05],\n",
       "       [-1.99754835e-05, -5.97971557e-05, -1.28811228e-06, ...,\n",
       "         4.21699771e-05,  2.60349319e-05,  9.70975841e-07]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.pinv(Omega_hat) @ Omega_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
